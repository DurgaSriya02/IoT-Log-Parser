{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d73fe46-ee8a-4aaa-9647-beb2b981f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import base64\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed4af13c-50e1-4044-8839-ee6706f6bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_logs(log_file):\n",
    "    \"\"\"\n",
    "    Parses logs with mixed formats, including error messages, Base64-encoded, and text-based logs.\n",
    "    Returns a structured DataFrame.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    skipped_lines = []\n",
    "\n",
    "    with open(log_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            entry = {}\n",
    "\n",
    "            # Handle JSON logs\n",
    "            try:\n",
    "                if line.startswith(\"{\") and line.endswith(\"}\"):\n",
    "                    json_data = json.loads(line)\n",
    "                    entry.update(json_data)\n",
    "\n",
    "                    # Decode nested 'details' if present\n",
    "                    if \"details\" in entry and isinstance(entry[\"details\"], dict):\n",
    "                        entry.update(entry[\"details\"])\n",
    "                        del entry[\"details\"]\n",
    "\n",
    "                    data.append(entry)\n",
    "                    continue\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "\n",
    "            # Handle Base64-encoded logs\n",
    "            if line.startswith(\"BASE64:\"):\n",
    "                try:\n",
    "                    encoded_data = line[7:].strip()\n",
    "                    decoded_json = json.loads(base64.b64decode(encoded_data).decode(\"utf-8\"))\n",
    "                    entry.update(decoded_json)\n",
    "\n",
    "                    # Decode 'details' if it exists\n",
    "                    if \"details\" in entry and isinstance(entry[\"details\"], dict):\n",
    "                        entry.update(entry[\"details\"])\n",
    "                        del entry[\"details\"]\n",
    "\n",
    "                    data.append(entry)\n",
    "                    continue\n",
    "                except (base64.binascii.Error, json.JSONDecodeError):\n",
    "                    skipped_lines.append(f\"Invalid Base64 log: {line}\")\n",
    "                    continue\n",
    "\n",
    "            # Handle error logs with patterns like '<Error> at <timestamp>'\n",
    "            error_match = re.search(r'(?P<Error>.+) at (?P<Timestamp>\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\.\\d+)', line)\n",
    "            if error_match:\n",
    "                entry[\"Error\"] = error_match.group(\"Error\")\n",
    "                entry[\"Timestamp\"] = error_match.group(\"Timestamp\")\n",
    "                data.append(entry)\n",
    "                continue\n",
    "\n",
    "            # Handle logs with errors and timestamps in reverse order\n",
    "            reverse_error_match = re.search(r'(?P<Timestamp>\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\.\\d+)\\s(?P<Error>.+)', line)\n",
    "            if reverse_error_match:\n",
    "                entry[\"Timestamp\"] = reverse_error_match.group(\"Timestamp\")\n",
    "                entry[\"Error\"] = reverse_error_match.group(\"Error\")\n",
    "                data.append(entry)\n",
    "                continue\n",
    "\n",
    "            # Handle action-based logs (e.g., user_423 performed purchase)\n",
    "            action_match = re.search(r'(\\w+)\\sperformed\\s(\\w+)\\sat\\s(\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\.\\d+)', line)\n",
    "            if action_match:\n",
    "                entry[\"User\"] = action_match.group(1)\n",
    "                entry[\"Action\"] = action_match.group(2)\n",
    "                entry[\"Timestamp\"] = action_match.group(3)\n",
    "                data.append(entry)\n",
    "                continue\n",
    "\n",
    "            # If no format matches, skip the line\n",
    "            skipped_lines.append(f\"Malformed log: {line}\")\n",
    "\n",
    "    # Convert parsed data to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Log skipped lines summary\n",
    "    if skipped_lines:\n",
    "        print(f\"Skipped lines due to parsing issues: {len(skipped_lines)} skipped lines.\")\n",
    "        print(\"Sample skipped lines:\")\n",
    "        for skipped_line in skipped_lines[:10]:  # Show the first 10 skipped lines only\n",
    "            print(skipped_line)\n",
    "\n",
    "    # Ensure 'Timestamp' column exists and is properly formatted\n",
    "    if \"Timestamp\" in df.columns:\n",
    "        df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"], errors=\"coerce\")\n",
    "    else:\n",
    "        print(\"Warning: No valid 'Timestamp' column found. Data may be incomplete.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08283d64-5773-4254-b611-96d983a01fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_visualizations(data):\n",
    "    \"\"\"\n",
    "    Generates visualizations for the parsed data.\n",
    "    Handles non-numeric columns by plotting their counts over time.\n",
    "    \"\"\"\n",
    "    if 'Timestamp' not in data.columns:\n",
    "        print(\"Error: 'Timestamp' column is missing. Cannot create time-based visualizations.\")\n",
    "        return\n",
    "\n",
    "    # Combine 'Timestamp' and 'timestamp' into a single column (if needed)\n",
    "    data['Final_Timestamp'] = data['Timestamp'].fillna(data.get('timestamp', pd.NaT))\n",
    "    data.drop(columns=['Timestamp', 'timestamp'], inplace=True)\n",
    "\n",
    "    # Drop rows without timestamps\n",
    "    data = data.dropna(subset=['Final_Timestamp'])\n",
    "\n",
    "    # Convert 'Final_Timestamp' to datetime\n",
    "    data['Final_Timestamp'] = pd.to_datetime(data['Final_Timestamp'], errors='coerce')\n",
    "\n",
    "    # Categorical Metrics (non-numeric columns)\n",
    "    non_numeric_metrics = ['Error', 'user', 'ip', 'event']\n",
    "\n",
    "    # Plot non-numeric metrics\n",
    "    for metric in non_numeric_metrics:\n",
    "        if metric in data.columns:\n",
    "            plt.figure(figsize=(12, 8))\n",
    "\n",
    "            # Count occurrences of each category over time\n",
    "            counts = data.groupby(['Final_Timestamp', metric]).size().reset_index(name='Count')\n",
    "            counts_pivot = counts.pivot(index='Final_Timestamp', columns=metric, values='Count').fillna(0)\n",
    "\n",
    "            # Plot as a stacked bar chart\n",
    "            counts_pivot.plot(kind='bar', stacked=True, figsize=(12, 8))\n",
    "            plt.title(f'{metric} Counts Over Time')\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel('Count')\n",
    "            plt.legend(title=metric)\n",
    "            plt.grid(axis='y')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    # Numeric Metrics (e.g., quantity, price)\n",
    "    numeric_metrics = ['quantity', 'price']\n",
    "    for metric in numeric_metrics:\n",
    "        if metric in data.columns:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(data['Final_Timestamp'], data[metric], label=f'{metric} over Time', color='blue')\n",
    "            plt.title(f'{metric} Over Time')\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel(metric)\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97e10379-5e5b-431a-84b0-8c19a737ce11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped lines due to parsing issues: 1572 skipped lines.\n",
      "Sample skipped lines:\n",
      "Malformed log: NullPointerException at line 42 2024-11-18T18:18:45.994516\n",
      "Malformed log: NullPointerException at line 42 2024-11-18T10:35:07.994582\n",
      "Malformed log: Malformed JSON object 2024-11-19T14:58:37.994586\n",
      "Malformed log: InvalidBase64: Data cannot be decoded 2024-11-18T11:57:39.994588\n",
      "Malformed log: TimeoutError: Connection to DB failed 2024-11-18T20:38:31.994617\n",
      "Malformed log: TimeoutError: Connection to DB failed 2024-11-19T08:46:04.994686\n",
      "Invalid Base64 log: BASE64:eyJ1c2VyIjogInVzZXJfNDE2IiwgInRpbWVzdGFtcCI6ICIyMDI0LTExLTE4VDE0OjM5OjAxLjk5NDY4OCIsICJpcCI6ICIyMTcuMjMxLjE0MS42MyIsICJldmVudCI6ICJsb2dvdXQiLCAiZGV0YWlscyI6IHsiaXRlbV9pZCI6IDgzOTIsICJxdWFudGl0eSI6IDUsICJwcmljZSI6IDYzNC45\n",
      "Malformed log: IndexOutOfBoundsException in module user_activity 2024-11-19T14:25:45.994726\n",
      "Malformed log: KeyError: 'action_type' 2024-11-19T13:15:04.994728\n",
      "Malformed log: TimeoutError: Connection to DB failed 2024-11-18T10:51:35.994753\n",
      "Parsed Data:\n",
      "                   Timestamp  \\\n",
      "0 2024-11-18 07:29:54.994500   \n",
      "1 2024-11-18 23:12:10.994511   \n",
      "2                        NaT   \n",
      "3 2024-11-18 05:09:49.994541   \n",
      "4                        NaT   \n",
      "\n",
      "                                               Error      user  \\\n",
      "0  IndexOutOfBoundsException in module user_activity       NaN   \n",
      "1                        user_423 performed purchase       NaN   \n",
      "2                                                NaN  user_345   \n",
      "3         user=user_639 ip=244.92.54.27 action=ERROR       NaN   \n",
      "4                                                NaN  user_686   \n",
      "\n",
      "                    timestamp              ip     event  item_id  quantity  \\\n",
      "0                         NaN             NaN       NaN      NaN       NaN   \n",
      "1                         NaN             NaN       NaN      NaN       NaN   \n",
      "2  2024-11-19T07:21:40.994519    212.47.97.84    logout   7403.0       1.0   \n",
      "3                         NaN             NaN       NaN      NaN       NaN   \n",
      "4  2024-11-18T10:37:33.994547  107.208.230.77  purchase   7451.0       3.0   \n",
      "\n",
      "    price  \n",
      "0     NaN  \n",
      "1     NaN  \n",
      "2  990.01  \n",
      "3     NaN  \n",
      "4  517.19  \n",
      "Columns in DataFrame: Index(['Timestamp', 'Error', 'user', 'timestamp', 'ip', 'event', 'item_id',\n",
      "       'quantity', 'price'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Provide the path to your log file\n",
    "log_file_path = 'assignment_prod.log'\n",
    "\n",
    "# Parse the logs\n",
    "parsed_data = parse_logs(log_file_path)\n",
    "\n",
    "# Inspect the parsed data\n",
    "print(\"Parsed Data:\")\n",
    "print(parsed_data.head())\n",
    "print(\"Columns in DataFrame:\", parsed_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434c1e17-e815-4d5f-bfae-24cc5fcc50b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "create_visualizations(parsed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93264782-6603-49b8-a278-9eda4532a566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
